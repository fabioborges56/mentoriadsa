{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mentoria Data Science Academy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import string\r\n",
    "import nltk\r\n",
    "import os\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, cohen_kappa_score, classification_report, confusion_matrix\r\n",
    "\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# Downloads do pacote NLTK\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('rslp')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.353105Z",
     "start_time": "2021-08-01T18:57:17.331075Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.0 Carregando os Dados"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T19:18:43.393429Z",
     "start_time": "2021-07-19T19:18:43.373439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_path = 'dados'\r\n",
    "df1 = pd.read_csv(os.path.join(data_path, 'posts.csv'), sep = '|')\r\n",
    "df2 = pd.read_csv(os.path.join(data_path, 'posts_2.csv'), sep = '|')\r\n",
    "df3 = pd.read_csv(os.path.join(data_path, 'posts_3.csv'), sep = '|')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.524078Z",
     "start_time": "2021-08-01T18:57:17.356075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.concat([df1, df2, df3], axis = 0)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.540074Z",
     "start_time": "2021-08-01T18:57:17.526074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# As colunas visits e likes não estão presentes em todos os dfs, então vamos remove-las \r\n",
    "df.drop(columns=['visits', 'likes'], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.588073Z",
     "start_time": "2021-08-01T18:57:17.543107Z"
    },
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df['area'] = df['area'].apply(lambda x: x.split('.')[0])"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.604077Z",
     "start_time": "2021-08-01T18:57:17.590075Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.0 Descrição dos dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Dimensão dos dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Número de exemplos:\", df.shape[0])\r\n",
    "print(\"Número de colunas:\", df.shape[1])"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.620077Z",
     "start_time": "2021-08-01T18:57:17.607076Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Tipo das colunas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Mostra o tipo de cada variável\r\n",
    "df.dtypes"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.652076Z",
     "start_time": "2021-08-01T18:57:17.624075Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Precisamos converter a variável date para formato de data para então podermos utilizar informações como dia da semana, fim de semana, ou há quantos meses/anos foi feita a pergunta."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Espaço reservado para trabalhar na variável date"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Variável target "
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T19:23:59.783562Z",
     "start_time": "2021-07-19T19:23:59.778559Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.1 Classes únicas\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check de quais classes o dataset possui\r\n",
    "df['area'].unique()"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.667078Z",
     "start_time": "2021-08-01T18:57:17.657078Z"
    },
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Número de classes diferentes: \", len(df['area'].unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Número de observações por classe:')\r\n",
    "df.groupby('area')['area'].count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classes\r\n",
    "\r\n",
    "Algumas classes estão com textos diferentes porém indicam a mesma coisa (Ex. 'direito-do-trabalho' e 'direito-do-trabalho/'). Iremos padronizar os textos para seguir com os seguintes labels:\r\n",
    "\r\n",
    "- Administrativo\r\n",
    "- Civil, Empresarial e do Consumidor\r\n",
    "- Familia\r\n",
    "- Trabalho\r\n",
    "- Penal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df['area'] = [\r\n",
    "    'Administrativo' if any(x in area for x in ['administrativo']) else\r\n",
    "    'Civil, Empresarial e do Consumidor' if any(x in area for x in ['civil', 'empresarial', 'consumidor']) else\r\n",
    "    'Familia' if any(x in area for x in ['familia']) else\r\n",
    "    'Trabalho' if any(x in area for x in ['trabalho']) else\r\n",
    "    'Penal' if any(x in area for x in ['penal']) else\r\n",
    "    area\r\n",
    "    for area in df['area']\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.groupby('area')['area'].count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Número de classes diferentes: \", len(df['area'].unique()))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.683077Z",
     "start_time": "2021-08-01T18:57:17.672076Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.2 Verificando o balanceamento das classes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Verifica em porcentagem o balanço das classes\r\n",
    "df['area'].value_counts(normalize=True)*100"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.732083Z",
     "start_time": "2021-08-01T18:57:17.686076Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## 2.0 Limpeza dos dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Visualizando os dados em formato RAW"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Printando as 10 primeiras strings em formato raw\r\n",
    "for i, post in enumerate(df['post'][:10]):\r\n",
    "    print(repr(df['post'].iloc[i]))\r\n",
    "    print('\\n')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.762075Z",
     "start_time": "2021-08-01T18:57:17.742076Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Criando um Pipeline de Limpeza"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Essa função substitui mais de um espaço em sequência (\\n\\t\\t\\t\\t) por apenas um espaço\r\n",
    "def remove_seq_breaklines(text):\r\n",
    "    clean_text = re.sub('\\s{2,}', ' ', text)\r\n",
    "    return clean_text"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.778076Z",
     "start_time": "2021-08-01T18:57:17.768076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Essa função substitui \\n por um espaço\r\n",
    "def remove_breaklines(text):\r\n",
    "    clean_text = re.sub('\\n', ' ', text)\r\n",
    "    return clean_text"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.793077Z",
     "start_time": "2021-08-01T18:57:17.783074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def remove_seq_spaces(text):\r\n",
    "    clean_text = re.sub('[ ]{2,}', '', text)\r\n",
    "    return clean_text"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.809073Z",
     "start_time": "2021-08-01T18:57:17.795074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "remove_seq_spaces('eu  eu')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.825076Z",
     "start_time": "2021-08-01T18:57:17.812083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Essa função remove os espaços que existem no fim e no inicio\r\n",
    "def remove_spaces(text):\r\n",
    "    clean_text = text.strip(' ')\r\n",
    "    clean_text\r\n",
    "    return clean_text"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.841074Z",
     "start_time": "2021-08-01T18:57:17.828078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Essa função remove as pontuações e os números (ex: datas serão removidas)\r\n",
    "def remove_punctuation(text):\r\n",
    "    clean_text  = \"\".join([char for char in text if char not in string.punctuation])\r\n",
    "    clean_text = re.sub('[0-9]+', '', clean_text)\r\n",
    "    clean_text = clean_text.replace('º', '')\r\n",
    "    return clean_text"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.856076Z",
     "start_time": "2021-08-01T18:57:17.850077Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Essa função converte textos em textos lowercase \r\n",
    "def convert_to_lower(text):\r\n",
    "    return text.lower()"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.872076Z",
     "start_time": "2021-08-01T18:57:17.860103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Essa função remove as stopwords\r\n",
    "def remove_stopwords(text):\r\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "    clean_text = [word for word in text.split(' ') if word not in stopwords]\r\n",
    "   \r\n",
    "    return \" \".join(clean_text)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.888077Z",
     "start_time": "2021-08-01T18:57:17.875080Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Essa função aplica o stemming nas palavras\r\n",
    "def stemmatization(text):\r\n",
    "    stemmer = nltk.stem.RSLPStemmer()\r\n",
    "    split_text = text.split(' ')\r\n",
    "    stem_text = [stemmer.stem(word) for word in split_text if word != \"\"]\r\n",
    "    stem_text = \" \".join(stem_text)\r\n",
    "    \r\n",
    "    return stem_text"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.904072Z",
     "start_time": "2021-08-01T18:57:17.890075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Função que aplica o pipeline\r\n",
    "def run_clean_pipeline(text):\r\n",
    "    clean_text = remove_breaklines(text)\r\n",
    "    clean_text = remove_seq_breaklines(clean_text)\r\n",
    "    clean_text = remove_spaces(clean_text)\r\n",
    "    clean_text = remove_punctuation(clean_text)\r\n",
    "    clean_text = convert_to_lower(clean_text)\r\n",
    "    clean_text = remove_stopwords(clean_text)\r\n",
    "    clean_text = stemmatization(clean_text)\r\n",
    "\r\n",
    "    return clean_text\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:17.920115Z",
     "start_time": "2021-08-01T18:57:17.906075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fazendo a limpeza das linhas através do pipeline\r\n",
    "clean_posts = list(df['post'].apply(run_clean_pipeline))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:48.785767Z",
     "start_time": "2021-08-01T18:57:17.923077Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Printa os 10 primeiras posts após a limpeza\r\n",
    "for post in clean_posts[:10]:\r\n",
    "    print(post)\r\n",
    "    print('\\n')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:48.801687Z",
     "start_time": "2021-08-01T18:57:48.791682Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df['clean_posts'] = clean_posts"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:48.832678Z",
     "start_time": "2021-08-01T18:57:48.807693Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.0 Preparação dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Codificação por Label"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convertendo variáveis target para valores numéricos\r\n",
    "\r\n",
    "le = LabelEncoder()\r\n",
    "le.fit(df['area'])\r\n",
    "df['area_encoded'] = le.transform(df['area'])"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:48.879676Z",
     "start_time": "2021-08-01T18:57:48.850676Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Split train/test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['area','area_encoded'], axis = 1), df['area_encoded'], test_size=0.33, shuffle = True, random_state = 42)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:49.354734Z",
     "start_time": "2021-08-01T18:57:48.882679Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Transformação TF-IDF"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T17:57:55.577533Z",
     "start_time": "2021-08-01T17:57:55.554536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\r\n",
    "\r\n",
    "train_tfidf = tfidf_vectorizer.fit_transform((X_train['clean_posts'])) \r\n",
    "test_tfidf = tfidf_vectorizer.transform((X_test['clean_posts']))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:49.401788Z",
     "start_time": "2021-08-01T18:57:49.374748Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.0 Modelo de Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = MultinomialNB()\r\n",
    "model.fit(train_tfidf, y_train)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:49.433744Z",
     "start_time": "2021-08-01T18:57:49.405745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ypred_nb = model.predict(test_tfidf)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:49.449742Z",
     "start_time": "2021-08-01T18:57:49.435744Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.0 Avaliação dos Modelos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optei por utilizar Accuracy, Precision e Kappa Score por ser um problema de classificação multi-classe.\n",
    "\n",
    "- Accuracy mede o quão bem o modelo está fazendo as previsões.\n",
    "- Precision mede o quão bem o modelo está fazendo as predições dos True Positives\n",
    "- Kappa score é uma medida de concordância entre 2 estimadores, no caso, o modelo e o y_test."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Avaliação Individual do Modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Accuracy:', accuracy_score(y_test, ypred_nb))\n",
    "print('Precision:', precision_score(y_test, ypred_nb, average = 'macro' ))\n",
    "print('Kappa Score:', cohen_kappa_score(y_test, ypred_nb))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:49.481749Z",
     "start_time": "2021-08-01T18:57:49.452744Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(classification_report(y_test, ypred_nb))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:49.513812Z",
     "start_time": "2021-08-01T18:57:49.484742Z"
    },
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.heatmap(confusion_matrix(y_test, ypred_nb),fmt = 'd', annot = True)\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('True Labels')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:57:49.796749Z",
     "start_time": "2021-08-01T18:57:49.517749Z"
    },
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Cross-Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_folds = 5\n",
    "kfold = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "kappa_list = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_ix, val_ix in kfold.split(df.drop('area', axis = 1), df['area']):\n",
    "    print('Fold: {} / {}'.format(i, num_folds))\n",
    "    \n",
    "    X_train_fold = df.iloc[train_ix]\n",
    "    y_train_fold = df['area'].iloc[train_ix]\n",
    "    \n",
    "    X_val_fold = df.iloc[val_ix]\n",
    "    y_val_fold = df['area'].iloc[val_ix]\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    train_tfidf_fold = tfidf_vectorizer.fit_transform((X_train_fold['clean_posts'])) \n",
    "    val_tfidf_fold = tfidf_vectorizer.transform((X_val_fold['clean_posts']))\n",
    "    \n",
    "    model = MultinomialNB()\n",
    "    model.fit(train_tfidf_fold, y_train_fold)\n",
    "    \n",
    "    y_pred_cv = model.predict(val_tfidf_fold)\n",
    "    \n",
    "    #metrics\n",
    "    \n",
    "    #Accuracy\n",
    "    acc = accuracy_score(y_val_fold, y_pred_cv)\n",
    "    accuracy_list.append(acc)\n",
    "    \n",
    "    #Precision\n",
    "    prec = precision_score(y_val_fold, y_pred_cv, average = 'macro')\n",
    "    precision_list.append(prec)\n",
    "    \n",
    "    #Kappa\n",
    "    kappa = cohen_kappa_score(y_val_fold, y_pred_cv)\n",
    "    kappa_list.append(kappa)\n",
    "    \n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:58:20.168878Z",
     "start_time": "2021-08-01T18:58:17.597778Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Cross-Validation Evaluation:')\n",
    "print('Accuracy: {:.2f} +/- {:.2f}'.format(np.mean(accuracy_list),np.std(accuracy_list)))\n",
    "print('Precision: {:.2f} +/- {:.2f}'.format(np.mean(precision_list),np.std(precision_list)))\n",
    "print('Kappa Score: {:.2f} +/- {:.2f}'.format(np.mean(kappa_list),np.std(kappa_list)))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:58:20.922760Z",
     "start_time": "2021-08-01T18:58:20.910757Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sugestões de Melhorias:\n",
    "\n",
    "- Utilização de Bigramas ou Trigramas antes da transformação TF-IDF com o próprio MultinomialNB\n",
    "- Utilização de SVM c/ Linear Kernel\n",
    "- Utilização de Redes Neurais - LSTM\n",
    "- SMOTE para um melhor balanceamento das classes\n",
    "- Análise da Nuvem de palavras pra cada classe, a fim de identificar quais termos aparecem com mais frequência dependendo da classe."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "f073831f69cd3c6d3e66726246945d904cffd54393bb30d63848c4ab17154cac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}